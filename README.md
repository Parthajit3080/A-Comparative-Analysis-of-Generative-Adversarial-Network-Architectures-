# A-Comparative-Analysis-of-Generative-Adversarial-Network-Architectures-


## ğŸ§  Overview
<p align="justify">
This project presents a detailed comparative study of <strong>Vanilla GAN</strong>, 
<strong>Wasserstein GAN (WGAN)</strong>, and <strong>WGAN with Gradient Penalty (WGAN-GP)</strong>, 
implemented across datasets of increasing complexityâ€”<strong>MNIST</strong>, 
<strong>CIFAR-10</strong>, and <strong>Anime Faces</strong>. The goal is to analyze 
<strong>training stability</strong>, <strong>sample quality</strong>, and 
<strong>theoretical robustness</strong> of each architecture.
</p>


---

## ğŸš€ Technologies Used
- Python 3.10+
- PyTorch  
- Torchvision  
- Matplotlib  
- NumPy  
- Scikit-learn  
- Frechet Inception Distance (torchmetrics)  
- Google Colab  
- Kaggle  

---

## ğŸ“Š Evaluation Metrics
- **FrÃ©chet Inception Distance (FID)**  
- **Inception Score (IS)**  
- **Visual Fidelity**  
- **Loss Dynamics**

---

## ğŸ–¼ Sample Outputs
<img width="1059" height="771" alt="image" src="https://github.com/user-attachments/assets/29d8e7c3-53d7-468b-8184-25bf98b37000" />
  

## ğŸ“Š Datasets
- MNIST  
- CIFAR-10  
- Anime Faces

---

## ğŸ“ˆ Key Insights
- WGAN-GP shows the best performance in terms of **training stability** and **image quality**.  
- âš Vanilla GAN is prone to **mode collapse** and **unstable gradients**.  
- FID score **correlates well with visual quality** across all datasets.

---

## ğŸ“„ Full Report
https://docs.google.com/document/d/14ILdxdc2qljDoKtwGzHv4sGrYAeMZnjfXZrNbiJSzLc/edit?usp=sharing

---

## ğŸ‘¨â€ğŸ’» Authors
- **Parthajit Das**  
- **Souvick Roy**  
- **Aditya Agarwal**

